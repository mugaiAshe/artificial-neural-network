{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-13T06:22:55.967954Z",
     "iopub.status.busy": "2024-01-13T06:22:55.967354Z",
     "iopub.status.idle": "2024-01-13T06:22:58.566658Z",
     "shell.execute_reply": "2024-01-13T06:22:58.565908Z",
     "shell.execute_reply.started": "2024-01-13T06:22:55.967913Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本项目基于Paddle的版本号为：2.6.0\r\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# 导入需要的包\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "from paddle.vision.transforms import ToTensor, Compose, Normalize, Resize, RandomRotation, RandomCrop, RandomHorizontalFlip, RandomErasing\n",
    "from paddle.vision.transforms import ColorJitter, CenterCrop\n",
    "import paddle.optimizer.lr as lrScheduler\n",
    "from paddle.io import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "print(\"本项目基于Paddle的版本号为：\"+paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解压数据集并进行数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-01-13T06:22:58.569709Z",
     "iopub.status.busy": "2024-01-13T06:22:58.568190Z",
     "iopub.status.idle": "2024-01-13T06:22:58.573491Z",
     "shell.execute_reply": "2024-01-13T06:22:58.572855Z",
     "shell.execute_reply.started": "2024-01-13T06:22:58.569677Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # zip_src: 需要解压的文件路径\n",
    "# # dst_dir: 解压后文件存放路径\n",
    "# test_zip_src = 'data/data256722/cat_12_test.zip'\n",
    "# train_zip_src = 'data/data256722/cat_12_train.zip'\n",
    "# test_src = './data/'\n",
    "# train_src = './data/'\n",
    "# def unzip_file(zip_path, extract_to_path, encoding='utf-8'):\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         # 获取压缩包中的所有文件列表\n",
    "#         file_list = zip_ref.namelist()\n",
    "\n",
    "#         # 将文件列表按照指定编码解码为字符串\n",
    "#         file_list_decoded = [file_name.encode(encoding).decode(encoding, 'replace') for file_name in file_list]\n",
    "\n",
    "#         # 解压缩文件\n",
    "#         for i, file_name in enumerate(file_list):\n",
    "#             zip_ref.extract(file_name, extract_to_path)\n",
    "#             # 重命名解压后的文件，使用解码后的文件名\n",
    "#             extracted_path = os.path.join(extract_to_path, file_name)\n",
    "#             renamed_path = os.path.join(extract_to_path, file_list_decoded[i])\n",
    "#             os.rename(extracted_path, renamed_path)\n",
    "\n",
    "\n",
    "# unzip_file(test_zip_src, test_src)\n",
    "# unzip_file(train_zip_src, train_src)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理并进行数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:22:58.574832Z",
     "iopub.status.busy": "2024-01-13T06:22:58.574347Z",
     "iopub.status.idle": "2024-01-13T06:23:03.831750Z",
     "shell.execute_reply": "2024-01-13T06:23:03.830817Z",
     "shell.execute_reply.started": "2024-01-13T06:22:58.574807Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件路径下图像数量： 2160\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#图像清洗\n",
    "def img_resize(data_dir):\n",
    "  print(\"文件路径下图像数量：\", len(os.listdir(data_dir)))\n",
    "  for img_name in os.listdir(data_dir):\n",
    "    img_dir = os.path.join(data_dir, img_name)\n",
    "    img = cv2.imread(img_dir)\n",
    "    if img is None:\n",
    "      continue\n",
    "      #os.remove(img_dir)#清除脏数据\n",
    "    else:\n",
    "      img_resize = cv2.resize(img, (224, 224))#重塑图像尺寸\n",
    "      cv2.imwrite(img_dir, img_resize)\n",
    "img_resize(\"/home/aistudio/work/cat_12_train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:23:03.833330Z",
     "iopub.status.busy": "2024-01-13T06:23:03.832945Z",
     "iopub.status.idle": "2024-01-13T06:23:03.845991Z",
     "shell.execute_reply": "2024-01-13T06:23:03.845382Z",
     "shell.execute_reply.started": "2024-01-13T06:23:03.833304Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#数据集划分train：valid = 8 ：2\n",
    "with open('/home/aistudio/work/train_list.txt', 'r') as f:\n",
    "    image_list = f.readlines()\n",
    "random.shuffle(image_list)\n",
    "cut = int(len(image_list) * 0.8)\n",
    "train_list = image_list[:cut]\n",
    "valid_list = image_list[cut:]\n",
    "      \n",
    "#创建train_list.txt\n",
    "with open('/home/aistudio/work/train.txt', 'w') as f:\n",
    "    for path in train_list:\n",
    "        img_paths = path.split()[0]\n",
    "        img_label = path.split()[1]\n",
    "        f.write(img_paths + ' ' + img_label + '\\n')\n",
    "\n",
    "#创建valid_list.txt\n",
    "with open('/home/aistudio/work/valid.txt', 'w') as f:\n",
    "    for path in valid_list:\n",
    "        img_paths = path.split()[0]\n",
    "        img_label = path.split()[1]\n",
    "        f.write(img_paths + ' ' + img_label + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:23:03.848081Z",
     "iopub.status.busy": "2024-01-13T06:23:03.847773Z",
     "iopub.status.idle": "2024-01-13T06:23:03.864135Z",
     "shell.execute_reply": "2024-01-13T06:23:03.863491Z",
     "shell.execute_reply.started": "2024-01-13T06:23:03.848058Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ResNetmean = [0.485, 0.456, 0.406]\n",
    "ResNetstd = [0.229, 0.224, 0.225]\n",
    "resnet_inv_mean = [-m/s for m, s in zip(ResNetmean, ResNetstd)]\n",
    "resnet_inv_std = [1/s for s in ResNetstd]\n",
    "\n",
    "ViTmean = [0.5, 0.5, 0.5]\n",
    "ViTstd = [0.5, 0.5, 0.5]\n",
    "vit_inv_mean = [-m/s for m, s in zip(ViTmean, ViTstd)]\n",
    "vit_inv_std = [1/s for s in ViTstd]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "img_size = 224\n",
    "\n",
    "data_dir = \"/home/aistudio/work\"\n",
    "# image_to_label = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "ResNetTransformTrain = Compose([\n",
    "    Resize((256, 256)), \n",
    "    CenterCrop((img_size, img_size)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=ResNetmean,std=ResNetstd,data_format='CHW'),\n",
    "    RandomErasing(prob=0.5, ratio=(0.01, 0.05))\n",
    "])\n",
    "ResNetTransformTest = Compose([\n",
    "    Resize((img_size, img_size)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=ResNetmean,std=ResNetstd,data_format='CHW')\n",
    "])\n",
    "\n",
    "ViTTransformTrain = Compose([\n",
    "    Resize((256, 256)), \n",
    "    CenterCrop((img_size, img_size)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=ViTmean,std=ViTstd,data_format='CHW'),\n",
    "    RandomErasing(prob=0.5, ratio=(0.01, 0.05))\n",
    "])\n",
    "ViTTransformTest = Compose([\n",
    "    Resize((img_size, img_size)),\n",
    "    ToTensor(), \n",
    "    Normalize(mean=ViTmean,std=ViTstd,data_format='CHW')\n",
    "])\n",
    "\n",
    "inverse_ResNetTransform = Compose([Normalize(mean=resnet_inv_mean, std=resnet_inv_std, data_format='CHW')])\n",
    "inverse_ViTTransform = Compose([Normalize(mean=vit_inv_mean, std=vit_inv_std, data_format='CHW')])\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, transform):\n",
    "        super(CatDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        if mode == 'train':\n",
    "            self.path = data_dir + '/train.txt'\n",
    "        else:\n",
    "            self.path = data_dir + '/valid.txt'\n",
    "        with open(self.path, \"r\") as file:\n",
    "            for line in file:\n",
    "                image, label = line.split(' ')\n",
    "                self.images.append(image)\n",
    "                self.labels.append(int(label.split('\\\\')[0]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 返回数据与标签\n",
    "        image = Image.open(self.data_dir + '/' + self.images[index]).convert('RGB')\n",
    "        if image is None:\n",
    "            print(self.data_dir + '/' + self.images[index])\n",
    "            return None, None\n",
    "        data = self.transform(image)\n",
    "        label = paddle.to_tensor(self.labels[index])\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "       return len(self.labels)\n",
    "\n",
    "ResNetTrainDataset = CatDataset(data_dir=data_dir, mode='train', transform=ResNetTransformTrain)\n",
    "ResNetTestDataset = CatDataset(data_dir=data_dir, mode='test', transform=ResNetTransformTest)\n",
    "\n",
    "ViTTrainDataset = CatDataset(data_dir=data_dir, mode='train', transform=ViTTransformTrain)\n",
    "ViTTestDataset = CatDataset(data_dir=data_dir, mode='test', transform=ViTTransformTest)\n",
    "\n",
    "ResNetTrainDataLoader = DataLoader(ResNetTrainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)\n",
    "ResNetTestDataLoader = DataLoader(ResNetTestDataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "ViTTrainDataLoader = DataLoader(ViTTrainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)\n",
    "ViTTestDataLoader = DataLoader(ViTTestDataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:25:50.807046Z",
     "iopub.status.busy": "2024-01-13T06:25:50.806463Z",
     "iopub.status.idle": "2024-01-13T06:25:53.648613Z",
     "shell.execute_reply": "2024-01-13T06:25:53.647489Z",
     "shell.execute_reply.started": "2024-01-13T06:25:50.807008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151272/151272 [00:01<00:00, 99970.95it/s] \r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for fc.weight. fc.weight receives a shape [2048, 1000], but the expected shape is [2048, 12].\r\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for fc.bias. fc.bias receives a shape [1000], but the expected shape is [12].\r\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n"
     ]
    }
   ],
   "source": [
    "resnetmodel = paddle.vision.models.resnet50(pretrained=True, num_classes=12)\n",
    "for param in resnetmodel.parameters():\n",
    "    param.stop_gradient = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:23:03.869207Z",
     "iopub.status.busy": "2024-01-13T06:23:03.868869Z",
     "iopub.status.idle": "2024-01-13T06:23:10.868861Z",
     "shell.execute_reply": "2024-01-13T06:23:10.867983Z",
     "shell.execute_reply.started": "2024-01-13T06:23:03.869185Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 14:23:03.896580   278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.8\r\n",
      "W0113 14:23:03.897814   278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for head.weight. head.weight receives a shape [768, 1000], but the expected shape is [768, 12].\r\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages/paddle/nn/layer/layers.py:2084: UserWarning: Skip loading for head.bias. head.bias receives a shape [1000], but the expected shape is [12].\r\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\r\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \r\n",
      "===========================================================================\r\n",
      "   Conv2D-1      [[4, 3, 224, 224]]    [4, 768, 14, 14]       590,592    \r\n",
      " PatchEmbed-1    [[4, 3, 224, 224]]     [4, 196, 768]            0       \r\n",
      "   Dropout-1      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-1     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-1       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "   Dropout-2     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-2       [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "   Dropout-3      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-1     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-1      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-2     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-3       [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-1        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "   Dropout-4      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-4       [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-1        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-1       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-3     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-5       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "   Dropout-5     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-6       [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "   Dropout-6      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-2     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-2      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-4     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-7       [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-2        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "   Dropout-7      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-8       [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-2        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-2       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-5     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-9       [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "   Dropout-8     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-10      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "   Dropout-9      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-3     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-3      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-6     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-11      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-3        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-10      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-12      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-3        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-3       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-7     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-13      [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "  Dropout-11     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-14      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "  Dropout-12      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-4     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-4      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-8     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-15      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-4        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-13      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-16      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-4        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-4       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  LayerNorm-9     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-17      [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "  Dropout-14     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-18      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "  Dropout-15      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-5     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-5      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-10     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-19      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-5        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-16      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-20      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-5        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-5       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-11     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-21      [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "  Dropout-17     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-22      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "  Dropout-18      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-6     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-6      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-12     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-23      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-6        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-19      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-24      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-6        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-6       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-13     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-25      [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "  Dropout-20     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-26      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "  Dropout-21      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-7     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-7      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-14     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-27      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-7        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-22      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-28      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-7        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-7       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-15     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-29      [[4, 197, 768]]       [4, 197, 2304]       1,769,472   \r\n",
      "  Dropout-23     [[4, 8, 197, 197]]    [4, 8, 197, 197]          0       \r\n",
      "   Linear-30      [[4, 197, 768]]       [4, 197, 768]         590,592    \r\n",
      "  Dropout-24      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Attention-8     [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "  Identity-8      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-16     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-31      [[4, 197, 768]]       [4, 197, 2304]       1,771,776   \r\n",
      "    GELU-8        [[4, 197, 2304]]      [4, 197, 2304]           0       \r\n",
      "  Dropout-25      [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "   Linear-32      [[4, 197, 2304]]      [4, 197, 768]        1,770,240   \r\n",
      "     Mlp-8        [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      "    Block-8       [[4, 197, 768]]       [4, 197, 768]            0       \r\n",
      " LayerNorm-17     [[4, 197, 768]]       [4, 197, 768]          1,536     \r\n",
      "   Linear-33         [[4, 768]]            [4, 12]             9,228     \r\n",
      "===========================================================================\r\n",
      "Total params: 47,842,572\r\n",
      "Trainable params: 47,842,572\r\n",
      "Non-trainable params: 0\r\n",
      "---------------------------------------------------------------------------\r\n",
      "Input size (MB): 2.30\r\n",
      "Forward/backward pass size (MB): 796.03\r\n",
      "Params size (MB): 182.50\r\n",
      "Estimated Total Size (MB): 980.84\r\n",
      "---------------------------------------------------------------------------\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 47842572, 'trainable_params': 47842572}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 图像分块、Embedding\n",
    "class PatchEmbed(nn.Layer):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        # 原始大小为int，转为tuple，即：img_size原始输入224，变换后为[224,224]\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        # 图像块的个数\n",
    "        num_patches = (img_size[1] // patch_size[1]) * \\\n",
    "            (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        # kernel_size=块大小，即每个块输出一个值，类似每个块展平后使用相同的全连接层进行处理\n",
    "        # 输入维度为3，输出维度为块向量长度\n",
    "        # 与原文中：分块、展平、全连接降维保持一致\n",
    "        # 输出为[B, C, H, W]\n",
    "        self.proj = nn.Conv2D(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            \"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        # [B, C, H, W] -> [B, C, H*W] ->[B, H*W, C]\n",
    "        x = self.proj(x).flatten(2).transpose((0, 2, 1))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Multi-head Attention\n",
    "class Attention(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads=8,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim**-0.5\n",
    "        # 计算 q,k,v 的转移矩阵\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias_attr=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        # 最终的线性层\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C = x.shape[1:]\n",
    "        # 线性变换\n",
    "        qkv = self.qkv(x).reshape((-1, N, 3, self.num_heads, C //\n",
    "                                   self.num_heads)).transpose((2, 0, 3, 1, 4))\n",
    "        # 分割 query key value\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        # Scaled Dot-Product Attention\n",
    "        # Matmul + Scale\n",
    "        attn = (q.matmul(k.transpose((0, 1, 3, 2)))) * self.scale\n",
    "        # SoftMax\n",
    "        attn = nn.functional.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        # Matmul\n",
    "        x = (attn.matmul(v)).transpose((0, 2, 1, 3)).reshape((-1, N, C))\n",
    "        # 线性变换\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mlp(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features=None,\n",
    "                 out_features=None,\n",
    "                 act_layer=nn.GELU,\n",
    "                 drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入层：线性变换\n",
    "        x = self.fc1(x)\n",
    "        # 应用激活函数\n",
    "        x = self.act(x)\n",
    "        # Dropout\n",
    "        x = self.drop(x)\n",
    "        # 输出层：线性变换\n",
    "        x = self.fc2(x)\n",
    "        # Dropout\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def drop_path(x, drop_prob=0., training=False):\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = paddle.to_tensor(1 - drop_prob)\n",
    "    shape = (paddle.shape(x)[0], ) + (1, ) * (x.ndim - 1)\n",
    "    random_tensor = keep_prob + paddle.rand(shape, dtype=x.dtype)\n",
    "    random_tensor = paddle.floor(random_tensor)\n",
    "    output = x.divide(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Layer):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "\n",
    "class Block(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop=0.,\n",
    "                 attn_drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer='nn.LayerNorm',\n",
    "                 epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.norm1 = eval(norm_layer)(dim, epsilon=epsilon)\n",
    "        # Multi-head Self-attention\n",
    "        self.attn = Attention(\n",
    "            dim,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            qk_scale=qk_scale,\n",
    "            attn_drop=attn_drop,\n",
    "            proj_drop=drop)\n",
    "        # DropPath\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else Identity()\n",
    "        self.norm2 = eval(norm_layer)(dim, epsilon=epsilon)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim,\n",
    "                       hidden_features=mlp_hidden_dim,\n",
    "                       act_layer=act_layer,\n",
    "                       drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-head Self-attention， Add， LayerNorm\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        # Feed Forward， Add， LayerNorm\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# 参数初始化配置\n",
    "trunc_normal_ = nn.initializer.TruncatedNormal(std=.02)\n",
    "zeros_ = nn.initializer.Constant(value=0.)\n",
    "ones_ = nn.initializer.Constant(value=1.)\n",
    "\n",
    "# 将输入 x 由 int 类型转为 tuple 类型\n",
    "def to_2tuple(x):\n",
    "    return tuple([x] * 2)\n",
    "\n",
    "# 定义一个什么操作都不进行的网络层\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 img_size=224,\n",
    "                 patch_size=16,\n",
    "                 in_chans=3,\n",
    "                 class_dim=1000,\n",
    "                 embed_dim=768,\n",
    "                 depth=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_ratio=4,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop_rate=0.,\n",
    "                 attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.,\n",
    "                 norm_layer='nn.LayerNorm',\n",
    "                 epsilon=1e-5,\n",
    "                 **args):\n",
    "        super().__init__()\n",
    "        self.class_dim = class_dim\n",
    "\n",
    "        self.num_features = self.embed_dim = embed_dim\n",
    "        # 图片分块和降维，块大小为patch_size，最终块向量维度为768\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim)\n",
    "        # 分块数量\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        # 可学习的位置编码\n",
    "        self.pos_embed = self.create_parameter(\n",
    "            shape=(1, num_patches + 1, embed_dim), default_initializer=zeros_)\n",
    "        self.add_parameter(\"pos_embed\", self.pos_embed)\n",
    "        # 人为追加class token，并使用该向量进行分类预测\n",
    "        self.cls_token = self.create_parameter(\n",
    "            shape=(1, 1, embed_dim), default_initializer=zeros_)\n",
    "        self.add_parameter(\"cls_token\", self.cls_token)\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = np.linspace(0, drop_path_rate, depth)\n",
    "        # transformer\n",
    "        self.blocks = nn.LayerList([\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                qk_scale=qk_scale,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[i],\n",
    "                norm_layer=norm_layer,\n",
    "                epsilon=epsilon) for i in range(depth)\n",
    "        ])\n",
    "\n",
    "        self.norm = eval(norm_layer)(embed_dim, epsilon=epsilon)\n",
    "\n",
    "        # Classifier head\n",
    "        self.head = nn.Linear(embed_dim,\n",
    "                              class_dim) if class_dim > 0 else Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed)\n",
    "        trunc_normal_(self.cls_token)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    # 参数初始化\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            zeros_(m.bias)\n",
    "            ones_(m.weight)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = paddle.shape(x)[0]\n",
    "        # 将图片分块，并调整每个块向量的维度\n",
    "        x = self.patch_embed(x)\n",
    "        # 将class token与前面的分块进行拼接\n",
    "        cls_tokens = self.cls_token.expand((B, -1, -1))\n",
    "        x = paddle.concat((cls_tokens, x), axis=1)\n",
    "        # 将编码向量中加入位置编码\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        # 堆叠 transformer 结构\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        # LayerNorm\n",
    "        x = self.norm(x)\n",
    "        # 提取分类 tokens 的输出\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取图像特征\n",
    "        x = self.forward_features(x)\n",
    "        # 图像分类\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "vitmodel = VisionTransformer(\n",
    "    patch_size=16,\n",
    "    embed_dim=768,\n",
    "    depth=8,\n",
    "    class_dim=12,\n",
    "    num_heads=8,\n",
    "    mlp_ratio=3,\n",
    "    qk_scale=768 ** -0.5,\n",
    "    )\n",
    "param = paddle.load('/home/aistudio/work/ViT_small_patch16_224_pretrained.pdparams')\n",
    "vitmodel.set_state_dict(param)\n",
    "paddle.summary(vitmodel, (4, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:27:04.608741Z",
     "iopub.status.busy": "2024-01-13T06:27:04.607974Z",
     "iopub.status.idle": "2024-01-13T06:27:04.621650Z",
     "shell.execute_reply": "2024-01-13T06:27:04.620867Z",
     "shell.execute_reply.started": "2024-01-13T06:27:04.608698Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 带Warmup的Cosine学习率衰减方式\n",
    "def get_scheduler(epochs, warmup_epochs, learning_rate):\n",
    "    base_scheduler = lrScheduler.CosineAnnealingDecay(learning_rate=learning_rate, T_max=epochs, eta_min=1e-5, verbose=False)\n",
    "    scheduler = lrScheduler.LinearWarmup(base_scheduler, warmup_epochs, 1e-5, learning_rate, last_epoch=-1, verbose=False)\n",
    "    return scheduler\n",
    "\n",
    "def train_epoch(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    acc_num = 0\n",
    "    total_samples = 0\n",
    "    nb = len(train_loader)\n",
    "    pbar = enumerate(train_loader)\n",
    "    pbar = tqdm(pbar, total=nb, colour='red')\n",
    "    pbar.set_description(f'EPOCH: {epoch:3d}')\n",
    "    for _, (_, data) in enumerate(pbar):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = model(x_data)\n",
    "        # print(predicts.shape, y_data.shape)\n",
    "        loss = criterion(predicts, y_data)\n",
    "        loss_item = loss.item()\n",
    "        acc_num += paddle.sum(predicts.argmax(1) == y_data.squeeze()).item()\n",
    "        total_samples += y_data.shape[0]\n",
    "        total_acc = acc_num / total_samples\n",
    "        current_lr = optim.get_lr()\n",
    "        loss.backward()\n",
    "        pbar.set_postfix(train_loss=f'{loss_item:5f}', train_acc=f'{total_acc:5f}', train_lr=f'{current_lr:5f}')\n",
    "        optim.step()\n",
    "        optim.clear_grad()\n",
    "    scheduler.step()\n",
    "\n",
    "@paddle.no_grad()\n",
    "def validation(model, test_loader):\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    total_samples = 0\n",
    "    nb = len(test_loader)\n",
    "    pbar = enumerate(test_loader)\n",
    "    pbar = tqdm(pbar, total=nb, colour='green')\n",
    "    pbar.set_description(f'EVAL')\n",
    "    for _, (_, data) in enumerate(pbar):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = model(x_data)\n",
    "        acc_num += paddle.sum(predicts.argmax(1) == y_data.squeeze()).item()\n",
    "        total_samples += y_data.shape[0]\n",
    "        y_data = paddle.unsqueeze(y_data, axis=1)\n",
    "        batch_acc = paddle.metric.accuracy(predicts, y_data).item()\n",
    "        total_acc = acc_num / total_samples\n",
    "        pbar.set_postfix(eval_batch_acc=f'{batch_acc:4f}', total_acc=f'{total_acc:4f}')\n",
    "    return total_acc\n",
    "\n",
    "def train(Model, TrainDataLoader, TestDataLoader, save_dir):\n",
    "    # Model.set_state_dict(paddle.load('{}/best.pdparams'.format(save_dir)))\n",
    "    best_acc = 0.8#validation(Model, TestDataLoader)\n",
    "    # Model.set_state_dict(paddle.load('{}/best.pdparams'.format(save_dir)))\n",
    "    start = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_epoch(Model, TrainDataLoader, epoch)\n",
    "        acc = validation(Model, TestDataLoader)\n",
    "        if acc > best_acc:\n",
    "            paddle.save(Model.state_dict(), '{}/best.pdparams'.format(save_dir))\n",
    "            best_acc = acc\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            paddle.save(Model.state_dict(),'{}/epoch_'.format(save_dir)+ str(epoch + 1) + '.pdparams')\n",
    "    paddle.save(Model.state_dict(), '{}/finished.pdparams'.format(save_dir))\n",
    "    end = time.time()\n",
    "    print('Training Cost ', (end-start) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:23:10.884012Z",
     "iopub.status.busy": "2024-01-13T06:23:10.883714Z",
     "iopub.status.idle": "2024-01-13T06:23:12.758722Z",
     "shell.execute_reply": "2024-01-13T06:23:12.757638Z",
     "shell.execute_reply.started": "2024-01-13T06:23:10.883990Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def ViT_small_patch16_224(pretrained=False, use_ssld=False, **kwargs):\n",
    "#     model = VisionTransformer(\n",
    "#         patch_size=16,\n",
    "#         embed_dim=768,\n",
    "#         depth=8,\n",
    "#         num_heads=8,\n",
    "#         mlp_ratio=3,\n",
    "#         qk_scale=768**-0.5,\n",
    "#         **kwargs)\n",
    "#     _load_pretrained(\n",
    "#         pretrained,\n",
    "#         model,\n",
    "#         MODEL_URLS[\"ViT_small_patch16_224\"],\n",
    "#         use_ssld=use_ssld)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:27:07.257015Z",
     "iopub.status.busy": "2024-01-13T06:27:07.256395Z",
     "iopub.status.idle": "2024-01-13T06:27:07.263841Z",
     "shell.execute_reply": "2024-01-13T06:27:07.262907Z",
     "shell.execute_reply.started": "2024-01-13T06:27:07.256977Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "EPOCHS = 5\n",
    "NUM_CLASSES = 12\n",
    "WARMUP_EPOCHS = 10\n",
    "LR = 0.00005\n",
    "SGD_LR = 0.001\n",
    "\n",
    "# 手动切换哪个具体模型Model = resnetmodel\n",
    "Model = vitmodel\n",
    "scheduler = get_scheduler(epochs=EPOCHS, warmup_epochs=WARMUP_EPOCHS, learning_rate=LR)\n",
    "# ResNet\n",
    "#optim = paddle.optimizer.Adam(learning_rate=scheduler, parameters=Model.parameters(), weight_decay=5e-4)\n",
    "# ViT\n",
    "optim = paddle.optimizer.SGD(learning_rate=SGD_LR, parameters=Model.parameters())\n",
    "criterion = paddle.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:27:09.480717Z",
     "iopub.status.busy": "2024-01-13T06:27:09.480094Z",
     "iopub.status.idle": "2024-01-13T06:28:17.458799Z",
     "shell.execute_reply": "2024-01-13T06:28:17.457747Z",
     "shell.execute_reply.started": "2024-01-13T06:27:09.480676Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   0: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.73it/s, train_acc=0.957755, train_loss=0.151257, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.48it/s, eval_batch_acc=0.958333, total_acc=0.962963]\r\n",
      "EPOCH:   1: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.71it/s, train_acc=0.962384, train_loss=0.111902, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.53it/s, eval_batch_acc=0.958333, total_acc=0.965278]\r\n",
      "EPOCH:   2: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.72it/s, train_acc=0.965278, train_loss=0.185192, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.50it/s, eval_batch_acc=0.958333, total_acc=0.962963]\r\n",
      "EPOCH:   3: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.70it/s, train_acc=0.968171, train_loss=0.107091, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.53it/s, eval_batch_acc=0.958333, total_acc=0.962963]\r\n",
      "EPOCH:   4: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.71it/s, train_acc=0.971065, train_loss=0.159793, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.54it/s, eval_batch_acc=0.958333, total_acc=0.962963]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost  1.1328781644503276 minutes\r\n"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "train(Model, ResNetTrainDataLoader, ResNetTestDataLoader, './work/ResNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:28:34.180475Z",
     "iopub.status.busy": "2024-01-13T06:28:34.179796Z",
     "iopub.status.idle": "2024-01-13T06:29:44.908132Z",
     "shell.execute_reply": "2024-01-13T06:29:44.907142Z",
     "shell.execute_reply.started": "2024-01-13T06:28:34.180409Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH:   0: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.71it/s, train_acc=0.981481, train_loss=0.092609, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.51it/s, eval_batch_acc=0.979167, total_acc=0.967593]\r\n",
      "EPOCH:   1: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.71it/s, train_acc=0.984375, train_loss=0.141011, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.51it/s, eval_batch_acc=0.958333, total_acc=0.967593]\r\n",
      "EPOCH:   2: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:10<00:00,  2.70it/s, train_acc=0.986111, train_loss=0.069530, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.52it/s, eval_batch_acc=0.958333, total_acc=0.967593]\r\n",
      "EPOCH:   3: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:10<00:00,  2.70it/s, train_acc=0.989005, train_loss=0.096674, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.52it/s, eval_batch_acc=0.958333, total_acc=0.967593]\r\n",
      "EPOCH:   4: 100%|\u001b[31m██████████\u001b[0m| 27/27 [00:09<00:00,  2.70it/s, train_acc=0.989005, train_loss=0.080218, train_lr=0.001000]\r\n",
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.50it/s, eval_batch_acc=0.958333, total_acc=0.969907]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cost  1.1787092804908752 minutes\r\n"
     ]
    }
   ],
   "source": [
    "# ViT\n",
    "train(Model, ViTTrainDataLoader, ViTTestDataLoader, './work/ViT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:28:25.829141Z",
     "iopub.status.busy": "2024-01-13T06:28:25.828502Z",
     "iopub.status.idle": "2024-01-13T06:28:29.009275Z",
     "shell.execute_reply": "2024-01-13T06:28:29.008310Z",
     "shell.execute_reply.started": "2024-01-13T06:28:25.829100Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.51it/s, eval_batch_acc=0.958333, total_acc=0.965278]\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9652777777777778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = paddle.load('./work/ResNet/best.pdparams')\n",
    "Model.set_state_dict(state_dict)\n",
    "Model.eval()\n",
    "validation(Model, ResNetTestDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T06:29:45.480560Z",
     "iopub.status.busy": "2024-01-13T06:29:45.479889Z",
     "iopub.status.idle": "2024-01-13T06:29:48.631896Z",
     "shell.execute_reply": "2024-01-13T06:29:48.631040Z",
     "shell.execute_reply.started": "2024-01-13T06:29:45.480523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVAL: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:02<00:00,  1.52it/s, eval_batch_acc=0.958333, total_acc=0.969907]\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9699074074074074"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = paddle.load('./work/ViT/best.pdparams')\n",
    "Model.set_state_dict(state_dict)\n",
    "Model.eval()\n",
    "validation(Model, ViTTestDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
