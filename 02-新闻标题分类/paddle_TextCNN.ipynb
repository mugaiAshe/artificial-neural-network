{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48a86a11-9f9a-4d06-8115-6aad63ed93dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:56:43.230918Z",
     "iopub.status.busy": "2024-01-13T05:56:43.230066Z",
     "iopub.status.idle": "2024-01-13T05:56:43.253290Z",
     "shell.execute_reply": "2024-01-13T05:56:43.252346Z",
     "shell.execute_reply.started": "2024-01-13T05:56:43.230880Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "from multiprocessing import cpu_count\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "paddle.enable_static()\r\n",
    "data_root_path='./data/'\r\n",
    " \r\n",
    "\r\n",
    "# 创建数据集\r\n",
    "def create_data_list(data_root_path):\r\n",
    "    with open(data_root_path + 'dev_list.txt', 'w') as f:\r\n",
    "        pass\r\n",
    "    with open(data_root_path + 'train_list.txt', 'w') as f:\r\n",
    "        pass\r\n",
    "\r\n",
    "    with open(os.path.join(data_root_path, 'dict_txt.txt'), 'r', encoding='utf-8') as f_data:\r\n",
    "        dict_txt = eval(f_data.readlines()[0])\r\n",
    "\r\n",
    "    with open(data_root_path + 'train.txt', 'r', encoding='utf-8') as f_data:\r\n",
    "        lines = f_data.readlines()\r\n",
    "\r\n",
    "    with open(os.path.join(data_root_path, 'dev.txt'), 'r', encoding='utf-8') as f_data:\r\n",
    "        lines = f_data.readlines()\r\n",
    "\r\n",
    "    for line in lines:\r\n",
    "        title = line.split('\\t')[0]\r\n",
    "        l = line.split('\\t')[-1].replace('\\n', '')\r\n",
    "        l = dict_reverse[l]\r\n",
    "        labs = \"\"\r\n",
    "        if True:\r\n",
    "            with open(os.path.join(data_root_path, 'dev_list.txt'), 'a', encoding='utf-8') as f_test:\r\n",
    "                for s in title:\r\n",
    "                    lab = str(dict_txt[s])\r\n",
    "                    labs = labs + lab + ','\r\n",
    "                labs = labs[:-1]\r\n",
    "                labs = labs + '\\t' + str(l) + '\\n'\r\n",
    "                f_test.write(labs)\r\n",
    "\r\n",
    "    with open(os.path.join(data_root_path, 'train.txt'), 'r', encoding='utf-8') as f_data:\r\n",
    "        lines = f_data.readlines()\r\n",
    "\r\n",
    "    for line in lines:\r\n",
    "        title = line.split('\\t')[0]\r\n",
    "        l = line.split('\\t')[-1].replace('\\n', '')\r\n",
    "        l = dict_reverse[l]\r\n",
    "        labs = \"\"\r\n",
    "        if True:\r\n",
    "            with open(os.path.join(data_root_path, 'train_list.txt'), 'a', encoding='utf-8') as f_test:\r\n",
    "                for s in title:\r\n",
    "                    lab = str(dict_txt[s])\r\n",
    "                    labs = labs + lab + ','\r\n",
    "                labs = labs[:-1]\r\n",
    "                labs = labs + '\\t' + str(l) + '\\n'\r\n",
    "                f_test.write(labs)\r\n",
    "    print(\"数据列表生成完成！\")\r\n",
    "\r\n",
    "Y_dict = {0: '财经',\r\n",
    " 1: '彩票',\r\n",
    " 2: '房产',\r\n",
    " 3: '股票',\r\n",
    " 4: '家居',\r\n",
    " 5: '教育',\r\n",
    " 6: '科技',\r\n",
    " 7: '社会',\r\n",
    " 8: '时尚',\r\n",
    " 9: '时政',\r\n",
    " 10: '体育',\r\n",
    " 11: '星座',\r\n",
    " 12: '游戏',\r\n",
    " 13: '娱乐'}\r\n",
    "\r\n",
    "dict_list = []\r\n",
    "\r\n",
    "for s in Y_dict:\r\n",
    "    dict_list.append([Y_dict[s], s])\r\n",
    "# 添加未知字符\r\n",
    "dict_reverse = dict(dict_list)\r\n",
    "end_dict = {\"<unk>\": 14}\r\n",
    "dict_reverse.update(end_dict)\r\n",
    "# 把这些字典保存到本地中\r\n",
    "with open(os.path.join(data_root_path, 'dict.txt'), 'w', encoding='utf-8') as f:\r\n",
    "    f.write(str(dict_reverse))\r\n",
    "\r\n",
    "\r\n",
    "# 把下载得数据生成一个字典\r\n",
    "def create_dict(data_path, dict_path):\r\n",
    "    dict_set = set()\r\n",
    "    # 统计有多少种类别，分别对应的id,并显示出来以供后面的预测应用\r\n",
    "    id_and_className = {}\r\n",
    "\r\n",
    "    # 读取已经下载得数据\r\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\r\n",
    "        lines = f.readlines()\r\n",
    "    # 把数据生成一个元组\r\n",
    "    for line in lines:\r\n",
    "        lineList = line.split('\\t')\r\n",
    "        classId = lineList[-1].replace('\\n', '')\r\n",
    "        title = lineList[0]\r\n",
    "        if classId not in id_and_className.keys():\r\n",
    "            id_and_className[classId] = lineList[1]\r\n",
    "\r\n",
    "        for s in title:\r\n",
    "            dict_set.add(s)\r\n",
    "    # 把元组转换成字典，一个字对应一个数字\r\n",
    "    dict_list = []\r\n",
    "    i = 0\r\n",
    "    for s in dict_set:\r\n",
    "        dict_list.append([s, i])\r\n",
    "        i += 1\r\n",
    "    # 添加未知字符\r\n",
    "    dict_txt = dict(dict_list)\r\n",
    "    end_dict = {\"<unk>\": i}\r\n",
    "    dict_txt.update(end_dict)\r\n",
    "    # 把这些字典保存到本地中\r\n",
    "    with open(dict_path, 'w', encoding='utf-8') as f:\r\n",
    "        f.write(str(dict_txt))\r\n",
    "    print(\"数据字典生成完成！\")\r\n",
    "    print('类Id及其类别名称:', id_and_className)\r\n",
    "\r\n",
    "\r\n",
    "# 获取字典的长度\r\n",
    "def get_dict_len(dict_path):\r\n",
    "    with open(dict_path, 'r', encoding='utf-8') as f:\r\n",
    "        line = eval(f.readlines()[0])\r\n",
    " \r\n",
    "    return len(line.keys())\r\n",
    "def data_mapper(sample):\r\n",
    "   data, label = sample\r\n",
    "   dataList=[]\r\n",
    "   for e in data.split(','):\r\n",
    "        if e=='':\r\n",
    "           print('meet blank')\r\n",
    "        else:\r\n",
    "            dataList.append(np.int64(e))\r\n",
    "   return dataList, int(label)\r\n",
    " \r\n",
    "# 创建数据读取器train_reader\r\n",
    "def train_reader(train_list_path):\r\n",
    "   def reader():\r\n",
    "       with open(train_list_path, 'r') as f:\r\n",
    "           lines = f.readlines()\r\n",
    "           # 打乱数据\r\n",
    "           np.random.shuffle(lines)\r\n",
    "           # 开始获取每张图像和标签\r\n",
    "           for line in lines:\r\n",
    "               data, label = line.split('\\t')\r\n",
    "               yield data, label\r\n",
    "   return paddle.reader.xmap_readers(data_mapper, reader, cpu_count(), 1024)\r\n",
    "#  创建数据读取器test_reader\r\n",
    "def test_reader(test_list_path):\r\n",
    "   def reader():\r\n",
    "       with open(test_list_path, 'r') as f:\r\n",
    "           lines = f.readlines()\r\n",
    "           for line in lines:\r\n",
    "               data, label = line.split('\\t')\r\n",
    "               yield data, label\r\n",
    "   return paddle.reader.xmap_readers(data_mapper, reader, cpu_count(), 1024)\r\n",
    " \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ba9cf6-c2b8-4b79-888f-4c9b9051a846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:56:43.255306Z",
     "iopub.status.busy": "2024-01-13T05:56:43.255004Z",
     "iopub.status.idle": "2024-01-13T05:57:10.297546Z",
     "shell.execute_reply": "2024-01-13T05:57:10.296151Z",
     "shell.execute_reply.started": "2024-01-13T05:56:43.255279Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据字典生成完成！\r\n",
      "类Id及其类别名称: {'科技': '科技\\n', '体育': '体育\\n', '时政': '时政\\n', '股票': '股票\\n', '娱乐': '娱乐\\n', '教育': '教育\\n', '家居': '家居\\n', '财经': '财经\\n', '房产': '房产\\n', '社会': '社会\\n', '游戏': '游戏\\n', '彩票': '彩票\\n', '星座': '星座\\n', '时尚': '时尚\\n'}\r\n",
      "数据列表生成完成！\r\n"
     ]
    }
   ],
   "source": [
    "#   网络定义\r\n",
    "def CNN_net(data, dict_dim, class_dim=14, emb_dim=128, hid_dim=128, hid_dim2=98):\r\n",
    "    emb = fluid.layers.embedding(input=data,size=[dict_dim, emb_dim])\r\n",
    "    conv_1 = fluid.nets.sequence_conv_pool(\r\n",
    "           input=emb,\r\n",
    "           num_filters=hid_dim,\r\n",
    "           filter_size=3,\r\n",
    "           act=\"tanh\",\r\n",
    "           pool_type=\"max\")\r\n",
    "    conv_2 = fluid.nets.sequence_conv_pool(\r\n",
    "           input=emb,\r\n",
    "           num_filters=hid_dim,\r\n",
    "           filter_size=4,\r\n",
    "           act=\"tanh\",\r\n",
    "           pool_type=\"max\")\r\n",
    "    conv_3 = fluid.nets.sequence_conv_pool(\r\n",
    "            input=emb,\r\n",
    "            num_filters=hid_dim2,\r\n",
    "            filter_size=4,\r\n",
    "            act=\"tanh\",\r\n",
    "            pool_type=\"max\")\r\n",
    "    fc1 = fluid.layers.fc(input=[conv_1, conv_2,conv_3], size=128, act='softmax')\r\n",
    "    bn = fluid.layers.batch_norm(input=fc1, act='relu')\r\n",
    "    fc2 = fluid.layers.fc(input= bn, size=64, act='softmax')\r\n",
    "    bn1 = fluid.layers.batch_norm(input=fc2, act='relu')\r\n",
    "    fc3 = fluid.layers.fc(input= bn1, size=class_dim, act='softmax')\r\n",
    "    return fc3\r\n",
    " \r\n",
    "# 定义绘制训练过程的损失值和准确率变化趋势的方法draw_train_process\r\n",
    "all_train_iter=0\r\n",
    "all_train_iters=[]\r\n",
    "all_train_costs=[]\r\n",
    "all_train_accs=[]\r\n",
    "def draw_train_process(title,iters,costs,accs,label_cost,lable_acc):\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=20)\r\n",
    "    plt.ylabel(\"cost/acc\", fontsize=20)\r\n",
    "    plt.plot(iters, costs,color='red',label=label_cost)\r\n",
    "    plt.plot(iters, accs,color='green',label=lable_acc)\r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.show()\r\n",
    " \r\n",
    "# 把生产的数据列表都放在自己的总类别文件夹中\r\n",
    "data_path = os.path.join(data_root_path, 'train.txt')\r\n",
    "dict_path = os.path.join(data_root_path, \"dict_txt.txt\")\r\n",
    "# 创建数据字典\r\n",
    "create_dict(data_path, dict_path)\r\n",
    "# 创建数据列表\r\n",
    "create_data_list(data_root_path)\r\n",
    " \r\n",
    "words = fluid.layers.data(name='words', shape=[1], dtype='int64', lod_level=1)\r\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n",
    "# 获取数据字典长度\r\n",
    "dict_dim = get_dict_len('./data/dict_txt.txt')\r\n",
    "# 获取卷积神经网络\r\n",
    "# 获取分类器\r\n",
    "model = CNN_net(words, dict_dim)\r\n",
    "# 获取损失函数和准确率\r\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\r\n",
    "avg_cost = fluid.layers.mean(cost)\r\n",
    "acc = fluid.layers.accuracy(input=model, label=label)\r\n",
    " \r\n",
    "# 获取预测程序\r\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\r\n",
    "# 定义优化方法\r\n",
    "optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.002)\r\n",
    "opt = optimizer.minimize(avg_cost)\r\n",
    " \r\n",
    "# 创建一个执行器，CPU训练速度比较慢\r\n",
    "# 定义使用CPU还是GPU，使用CPU时use_cuda = False,使用GPU时use_cuda = True\r\n",
    "use_cuda =  False\r\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n",
    "#place = fluid.CPUPlace()\r\n",
    "#place = fluid.CUDAPlace(0)\r\n",
    "exe = fluid.Executor(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9b855a-5835-4d67-9f93-7263233980e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T05:57:10.299382Z",
     "iopub.status.busy": "2024-01-13T05:57:10.298928Z",
     "iopub.status.idle": "2024-01-13T07:38:08.876355Z",
     "shell.execute_reply": "2024-01-13T07:38:08.874960Z",
     "shell.execute_reply.started": "2024-01-13T05:57:10.299352Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass:0, Batch:0, Cost:2.63319, Acc:0.03906\r\n",
      "Train Pass:0, Batch:100, Cost:1.16956, Acc:0.69531\r\n",
      "Train Pass:0, Batch:200, Cost:0.81127, Acc:0.80469\r\n",
      "Train Pass:0, Batch:300, Cost:0.77494, Acc:0.79688\r\n",
      "Train Pass:0, Batch:400, Cost:0.88253, Acc:0.72656\r\n",
      "Train Pass:0, Batch:500, Cost:0.69675, Acc:0.75781\r\n",
      "Train Pass:0, Batch:600, Cost:0.74678, Acc:0.74219\r\n",
      "Train Pass:0, Batch:700, Cost:0.49288, Acc:0.85938\r\n",
      "Train Pass:0, Batch:800, Cost:0.62903, Acc:0.79688\r\n",
      "Train Pass:0, Batch:900, Cost:0.53129, Acc:0.89062\r\n",
      "Train Pass:0, Batch:1000, Cost:0.59342, Acc:0.85938\r\n",
      "Train Pass:0, Batch:1100, Cost:0.56626, Acc:0.85156\r\n",
      "Train Pass:0, Batch:1200, Cost:0.54455, Acc:0.82812\r\n",
      "Train Pass:0, Batch:1300, Cost:0.70999, Acc:0.80469\r\n",
      "Train Pass:0, Batch:1400, Cost:0.44355, Acc:0.89844\r\n",
      "Train Pass:0, Batch:1500, Cost:0.55202, Acc:0.82812\r\n",
      "Train Pass:0, Batch:1600, Cost:0.31157, Acc:0.94531\r\n",
      "Train Pass:0, Batch:1700, Cost:0.55303, Acc:0.81250\r\n",
      "Train Pass:0, Batch:1800, Cost:0.59024, Acc:0.82031\r\n",
      "Train Pass:0, Batch:1900, Cost:0.45591, Acc:0.84375\r\n",
      "Train Pass:0, Batch:2000, Cost:0.42477, Acc:0.90625\r\n",
      "Train Pass:0, Batch:2100, Cost:0.44794, Acc:0.86719\r\n",
      "Train Pass:0, Batch:2200, Cost:0.51255, Acc:0.83594\r\n",
      "Train Pass:0, Batch:2300, Cost:0.42290, Acc:0.87500\r\n",
      "Train Pass:0, Batch:2400, Cost:0.48972, Acc:0.84375\r\n",
      "Train Pass:0, Batch:2500, Cost:0.57068, Acc:0.78125\r\n",
      "Train Pass:0, Batch:2600, Cost:0.62464, Acc:0.80469\r\n",
      "Train Pass:0, Batch:2700, Cost:0.56190, Acc:0.84375\r\n",
      "Train Pass:0, Batch:2800, Cost:0.48946, Acc:0.84375\r\n",
      "Train Pass:0, Batch:2900, Cost:0.54119, Acc:0.80469\r\n",
      "Train Pass:0, Batch:3000, Cost:0.42852, Acc:0.83594\r\n",
      "Train Pass:0, Batch:3100, Cost:0.50942, Acc:0.85938\r\n",
      "Train Pass:0, Batch:3200, Cost:0.36057, Acc:0.89062\r\n",
      "Train Pass:0, Batch:3300, Cost:0.35851, Acc:0.87500\r\n",
      "Train Pass:0, Batch:3400, Cost:0.46811, Acc:0.86719\r\n",
      "Train Pass:0, Batch:3500, Cost:0.45863, Acc:0.88281\r\n",
      "Train Pass:0, Batch:3600, Cost:0.36130, Acc:0.89844\r\n",
      "Train Pass:0, Batch:3700, Cost:0.40056, Acc:0.86719\r\n",
      "Train Pass:0, Batch:3800, Cost:0.36246, Acc:0.90625\r\n",
      "Train Pass:0, Batch:3900, Cost:0.30131, Acc:0.89844\r\n",
      "Train Pass:0, Batch:4000, Cost:0.28587, Acc:0.89844\r\n",
      "Train Pass:0, Batch:4100, Cost:0.40373, Acc:0.87500\r\n",
      "Train Pass:0, Batch:4200, Cost:0.54420, Acc:0.82812\r\n",
      "Train Pass:0, Batch:4300, Cost:0.28122, Acc:0.90625\r\n",
      "Train Pass:0, Batch:4400, Cost:0.35011, Acc:0.88281\r\n",
      "Train Pass:0, Batch:4500, Cost:0.34413, Acc:0.92188\r\n",
      "Train Pass:0, Batch:4600, Cost:0.39719, Acc:0.89844\r\n",
      "Train Pass:0, Batch:4700, Cost:0.32482, Acc:0.90625\r\n",
      "Train Pass:0, Batch:4800, Cost:0.37016, Acc:0.88281\r\n",
      "Train Pass:0, Batch:4900, Cost:0.30642, Acc:0.91406\r\n",
      "Train Pass:0, Batch:5000, Cost:0.29547, Acc:0.89062\r\n",
      "Train Pass:0, Batch:5100, Cost:0.35939, Acc:0.88281\r\n",
      "Train Pass:0, Batch:5200, Cost:0.26206, Acc:0.90625\r\n",
      "Train Pass:0, Batch:5300, Cost:0.33962, Acc:0.89062\r\n",
      "Train Pass:0, Batch:5400, Cost:0.38110, Acc:0.87500\r\n",
      "Train Pass:0, Batch:5500, Cost:0.39945, Acc:0.87500\r\n",
      "Train Pass:0, Batch:5600, Cost:0.33659, Acc:0.87500\r\n",
      "Train Pass:0, Batch:5700, Cost:0.36605, Acc:0.87500\r\n",
      "Train Pass:0, Batch:5800, Cost:0.35817, Acc:0.92969\r\n",
      "Test:0, Cost:0.35352, ACC:0.89436\r\n",
      "Train Pass:1, Batch:0, Cost:0.33317, Acc:0.91406\r\n",
      "Train Pass:1, Batch:100, Cost:0.32697, Acc:0.91406\r\n",
      "Train Pass:1, Batch:200, Cost:0.25632, Acc:0.92188\r\n",
      "Train Pass:1, Batch:300, Cost:0.31023, Acc:0.87500\r\n",
      "Train Pass:1, Batch:400, Cost:0.25124, Acc:0.90625\r\n",
      "Train Pass:1, Batch:500, Cost:0.37116, Acc:0.90625\r\n",
      "Train Pass:1, Batch:600, Cost:0.29610, Acc:0.91406\r\n",
      "Train Pass:1, Batch:700, Cost:0.15663, Acc:0.96094\r\n",
      "Train Pass:1, Batch:800, Cost:0.34596, Acc:0.91406\r\n",
      "Train Pass:1, Batch:900, Cost:0.36167, Acc:0.89844\r\n",
      "Train Pass:1, Batch:1000, Cost:0.32568, Acc:0.89062\r\n",
      "Train Pass:1, Batch:1100, Cost:0.22856, Acc:0.94531\r\n",
      "Train Pass:1, Batch:1200, Cost:0.34423, Acc:0.89062\r\n",
      "Train Pass:1, Batch:1300, Cost:0.38283, Acc:0.90625\r\n",
      "Train Pass:1, Batch:1400, Cost:0.50105, Acc:0.83594\r\n",
      "Train Pass:1, Batch:1500, Cost:0.34960, Acc:0.89844\r\n",
      "Train Pass:1, Batch:1600, Cost:0.34311, Acc:0.90625\r\n",
      "Train Pass:1, Batch:1700, Cost:0.31909, Acc:0.91406\r\n",
      "Train Pass:1, Batch:1800, Cost:0.32727, Acc:0.89062\r\n",
      "Train Pass:1, Batch:1900, Cost:0.28708, Acc:0.92188\r\n",
      "Train Pass:1, Batch:2000, Cost:0.26908, Acc:0.94531\r\n",
      "Train Pass:1, Batch:2100, Cost:0.41424, Acc:0.88281\r\n",
      "Train Pass:1, Batch:2200, Cost:0.36112, Acc:0.89062\r\n",
      "Train Pass:1, Batch:2300, Cost:0.38296, Acc:0.89844\r\n",
      "Train Pass:1, Batch:2400, Cost:0.32642, Acc:0.92188\r\n",
      "Train Pass:1, Batch:2500, Cost:0.37137, Acc:0.89062\r\n",
      "Train Pass:1, Batch:2600, Cost:0.26062, Acc:0.93750\r\n",
      "Train Pass:1, Batch:2700, Cost:0.37228, Acc:0.89844\r\n",
      "Train Pass:1, Batch:2800, Cost:0.25572, Acc:0.92188\r\n",
      "Train Pass:1, Batch:2900, Cost:0.25251, Acc:0.90625\r\n",
      "Train Pass:1, Batch:3000, Cost:0.19505, Acc:0.93750\r\n",
      "Train Pass:1, Batch:3100, Cost:0.26981, Acc:0.89844\r\n",
      "Train Pass:1, Batch:3200, Cost:0.28133, Acc:0.91406\r\n",
      "Train Pass:1, Batch:3300, Cost:0.41135, Acc:0.86719\r\n",
      "Train Pass:1, Batch:3400, Cost:0.27714, Acc:0.93750\r\n",
      "Train Pass:1, Batch:3500, Cost:0.41803, Acc:0.89062\r\n",
      "Train Pass:1, Batch:3600, Cost:0.29207, Acc:0.92969\r\n",
      "Train Pass:1, Batch:3700, Cost:0.17713, Acc:0.96094\r\n",
      "Train Pass:1, Batch:3800, Cost:0.33284, Acc:0.89062\r\n",
      "Train Pass:1, Batch:3900, Cost:0.22220, Acc:0.92188\r\n",
      "Train Pass:1, Batch:4000, Cost:0.27622, Acc:0.92188\r\n",
      "Train Pass:1, Batch:4100, Cost:0.17504, Acc:0.93750\r\n",
      "Train Pass:1, Batch:4200, Cost:0.34376, Acc:0.87500\r\n",
      "Train Pass:1, Batch:4300, Cost:0.21220, Acc:0.92969\r\n",
      "Train Pass:1, Batch:4400, Cost:0.24712, Acc:0.92188\r\n",
      "Train Pass:1, Batch:4500, Cost:0.29042, Acc:0.91406\r\n",
      "Train Pass:1, Batch:4600, Cost:0.29070, Acc:0.91406\r\n",
      "Train Pass:1, Batch:4700, Cost:0.37757, Acc:0.89844\r\n",
      "Train Pass:1, Batch:4800, Cost:0.26007, Acc:0.95312\r\n",
      "Train Pass:1, Batch:4900, Cost:0.35639, Acc:0.86719\r\n",
      "Train Pass:1, Batch:5000, Cost:0.22282, Acc:0.93750\r\n",
      "Train Pass:1, Batch:5100, Cost:0.23048, Acc:0.91406\r\n",
      "Train Pass:1, Batch:5200, Cost:0.22457, Acc:0.93750\r\n",
      "Train Pass:1, Batch:5300, Cost:0.23662, Acc:0.94531\r\n",
      "Train Pass:1, Batch:5400, Cost:0.21938, Acc:0.94531\r\n",
      "Train Pass:1, Batch:5500, Cost:0.18984, Acc:0.94531\r\n",
      "Train Pass:1, Batch:5600, Cost:0.33878, Acc:0.89844\r\n",
      "Train Pass:1, Batch:5700, Cost:0.26244, Acc:0.90625\r\n",
      "Train Pass:1, Batch:5800, Cost:0.32104, Acc:0.92188\r\n",
      "Test:1, Cost:0.28852, ACC:0.91284\r\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13853/4158902664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m    \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m fluid.io.save_inference_model(os.path.join(save_dir, 'model_state.pdparams'),\n\u001b[0m\u001b[1;32m     40\u001b[0m                            \u001b[0mfeeded_var_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                            \u001b[0mtarget_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# 进行参数初始化\r\n",
    "exe.run(fluid.default_startup_program())\r\n",
    "train_reader = paddle.batch(reader=train_reader('./data/train_list.txt'), batch_size=128)\r\n",
    "test_reader = paddle.batch(reader=test_reader('./data/dev_list.txt'), batch_size=128)\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[words, label])\r\n",
    " \r\n",
    "EPOCH_NUM=1\r\n",
    "model_save_dir = './infer_model/'\r\n",
    "# 开始训练\r\n",
    " \r\n",
    "for pass_id in range(EPOCH_NUM):\r\n",
    "   # 进行训练\r\n",
    "   for batch_id, data in enumerate(train_reader()):\r\n",
    "       train_cost, train_acc = exe.run(program=fluid.default_main_program(),\r\n",
    "                            feed=feeder.feed(data),\r\n",
    "                            fetch_list=[avg_cost, acc])\r\n",
    "       all_train_iter = all_train_iter + 100\r\n",
    "       all_train_iters.append(all_train_iter)\r\n",
    "       all_train_costs.append(train_cost[0])\r\n",
    "       all_train_accs.append(train_acc[0])\r\n",
    "       if batch_id % 100 == 0:\r\n",
    "           print('Train Pass:%d, Batch:%d, Cost:%0.5f, Acc:%0.5f' % (pass_id, batch_id, train_cost[0], train_acc[0]))\r\n",
    "   # 进行测试\r\n",
    "   test_costs = []\r\n",
    "   test_accs = []\r\n",
    "   for batch_id, data in enumerate(test_reader()):\r\n",
    "       test_cost, test_acc = exe.run(program=test_program,\r\n",
    "                                             feed=feeder.feed(data),\r\n",
    "                                             fetch_list=[avg_cost, acc])\r\n",
    "       test_costs.append(test_cost[0])\r\n",
    "       test_accs.append(test_acc[0])\r\n",
    "   # 计算平均预测损失在和准确率\r\n",
    "   test_cost = (sum(test_costs) / len(test_costs))\r\n",
    "   test_acc = (sum(test_accs) / len(test_accs))\r\n",
    "   print('Test:%d, Cost:%0.5f, ACC:%0.5f' % (pass_id, test_cost, test_acc))\r\n",
    " \r\n",
    "if not os.path.exists(model_save_dir):\r\n",
    "   os.makedirs(model_save_dir)\r\n",
    "fluid.io.save_inference_model(os.path.join(save_dir=model_save_dir, 'model_state.pdparams'),\r\n",
    "                           feeded_var_names=[words.name],\r\n",
    "                           target_vars=[model],\r\n",
    "                           executor=exe)\r\n",
    "print('训练模型保存完成！')\r\n",
    "draw_train_process(\"training\", all_train_iters, all_train_costs, all_train_accs, \"trainning cost\", \"trainning acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3240d-cf1e-467d-af62-2e2019e5d1d9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T07:38:08.877263Z",
     "iopub.status.idle": "2024-01-13T07:38:08.877715Z",
     "shell.execute_reply": "2024-01-13T07:38:08.877564Z",
     "shell.execute_reply.started": "2024-01-13T07:38:08.877549Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载在验证集上效果最优的一轮的模型参数\r\n",
    "import os\r\n",
    "import paddle\r\n",
    "\r\n",
    "params_path = './infer_model/model_state.pdparams'\r\n",
    "if params_path and os.path.isfile(params_path):\r\n",
    "    # 加载模型参数\r\n",
    "    state_dict = paddle.load(params_path)\r\n",
    "    model.set_dict(state_dict)\r\n",
    "    print(\"Loaded parameters from %s\" % params_path)\r\n",
    "\r\n",
    "    # 测试最优模型参数在验证集上的分数\r\n",
    "evaluate(model, criterion, metric, dev_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
