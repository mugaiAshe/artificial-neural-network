{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5b24ea-287c-4507-879a-8cc9fc659e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:13:52.253382Z",
     "iopub.status.busy": "2024-01-14T00:13:52.252530Z",
     "iopub.status.idle": "2024-01-14T00:14:44.201549Z",
     "shell.execute_reply": "2024-01-14T00:14:44.200558Z",
     "shell.execute_reply.started": "2024-01-14T00:13:52.253349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting attrdict==2.0.1\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from attrdict==2.0.1) (1.16.0)\r\n",
      "Installing collected packages: attrdict\r\n",
      "Successfully installed attrdict-2.0.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting paddlenlp==2.1.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4b/e5/ea8e2b478135e7cee84e8079daea68c918440e7209cf4a44b7ef5fceec7c/paddlenlp-2.1.0-py3-none-any.whl (742 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m742.9/742.9 kB\u001b[0m \u001b[31m674.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (0.4.4)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (4.1.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (0.70.11.1)\r\n",
      "Collecting paddlefsl==1.0.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/5d/65/9970dd09309eb673303206befc9f2fdc9c2d29d31f002ae8d6c7b442f562/paddlefsl-1.0.0-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m887.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (0.42.1)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.1.0) (1.2.2)\r\n",
      "Collecting requests~=2.24.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m801.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\r\n",
      "\u001b[?25hCollecting tqdm~=4.27.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/16/33/6d8bd6a7c4238f383426b7593bf05bfd6d9e1f10c3084b56c0f14d973754/tqdm-4.27.0-py2.py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m545.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting pillow==8.2.0\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/33/34/542152297dcc6c47a9dcb0685eac6d652d878ed3cea83bf2b23cb988e857/Pillow-8.2.0-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m584.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy~=1.19.2\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m639.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp==2.1.0) (1.16.0)\r\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp==2.1.0) (0.3.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp==2.1.0) (0.22.1)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp==2.1.0) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp==2.1.0) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp==2.1.0) (1.25.6)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp==2.1.0) (2.8)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.1.0) (0.14.1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.1.0) (1.3.0)\r\n",
      "Installing collected packages: tqdm, requests, pillow, numpy, paddlefsl, paddlenlp\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] 权限不够: 'WHEEL'\r\n",
      "Consider using the `--user` option or check the permissions.\r\n",
      "\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: attrdict==2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from attrdict==2.0.1) (1.16.0)\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting PyYAML==5.4.1\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m539.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: PyYAML\r\n",
      "  Attempting uninstall: PyYAML\r\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m    Found existing installation: PyYAML 5.1.2\r\n",
      "    Uninstalling PyYAML-5.1.2:\r\n",
      "      Successfully uninstalled PyYAML-5.1.2\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mSuccessfully installed PyYAML-5.4.1\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Collecting subword_nmt==0.3.7\r\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl (26 kB)\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: subword_nmt\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mSuccessfully installed subword_nmt-0.3.7\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: jieba==0.42.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (0.42.1)\r\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qdm (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages)\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install attrdict==2.0.1\n",
    "!pip install paddlenlp==2.1.0\n",
    "!pip install attrdict==2.0.1\n",
    "!pip install PyYAML==5.4.1\n",
    "!pip install subword_nmt==0.3.7\n",
    "!pip install jieba==0.42.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df8c7ca-3694-4b79-a87a-175da848a9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:52:05.829359Z",
     "iopub.status.busy": "2024-01-14T00:52:05.828842Z",
     "iopub.status.idle": "2024-01-14T00:52:05.835555Z",
     "shell.execute_reply": "2024-01-14T00:52:05.834706Z",
     "shell.execute_reply.started": "2024-01-14T00:52:05.829328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/transformer_mt\r\n"
     ]
    }
   ],
   "source": [
    "%cd transformer_mt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128e736a-0e95-4e73-8270-018ddd67ef14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:15:38.866764Z",
     "iopub.status.busy": "2024-01-14T00:15:38.865637Z",
     "iopub.status.idle": "2024-01-14T00:15:48.809525Z",
     "shell.execute_reply": "2024-01-14T00:15:48.808538Z",
     "shell.execute_reply.started": "2024-01-14T00:15:38.866730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  transformer_mt.zip\r\n",
      "  inflating: transformer_mt/1918692.ipynb  \r\n",
      "  inflating: transformer_mt/preprocess.sh  \r\n",
      "  inflating: transformer_mt/utils.py  \r\n",
      "  inflating: transformer_mt/__pycache__/utils.cpython-37.pyc  \r\n",
      "  inflating: transformer_mt/train_dev_test.tar.gz  \r\n",
      "  inflating: transformer_mt/get_data_and_model.sh  \r\n",
      "  inflating: transformer_mt/requirements.txt  \r\n",
      "  inflating: transformer_mt/mosesdecoder.tar.gz  \r\n",
      "  inflating: transformer_mt/transformer.base.yaml  \r\n",
      "/home/aistudio/work/transformer_mt\r\n",
      "jieba tokenize...\r\n",
      "Building prefix dict from the default dictionary ...\r\n",
      "Dumping model to file cache /tmp/jieba.cache\r\n",
      "Loading model cost 0.817 seconds.\r\n",
      "Prefix dict has been built successfully.\r\n",
      "source learn-bpe and apply-bpe...\r\n",
      "no pair has frequency >= 2. Stopping\r\n",
      "target learn-bpe and apply-bpe...\r\n",
      "no pair has frequency >= 2. Stopping\r\n",
      "source get-vocab. if loading pretrained model, use its vocab.\r\n",
      "target get-vocab. if loading pretrained model, use its vocab.\r\n",
      "Over.\r\n",
      "Over.\r\n"
     ]
    }
   ],
   "source": [
    "# !unzip -o transformer_mt.zip\n",
    "\n",
    "\n",
    "!bash preprocess.sh\n",
    "# 下载预训练模型\n",
    "!bash get_data_and_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73516ac-f763-4290-a8ba-c7233deabee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T01:09:04.459822Z",
     "iopub.status.busy": "2024-01-14T01:09:04.459264Z",
     "iopub.status.idle": "2024-01-14T01:09:04.466947Z",
     "shell.execute_reply": "2024-01-14T01:09:04.466235Z",
     "shell.execute_reply.started": "2024-01-14T01:09:04.459789Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from attrdict import AttrDict\n",
    "import jieba\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import paddle\n",
    "import paddle.distributed as dist\n",
    "from paddle.io import DataLoader,BatchSampler\n",
    "from paddlenlp.data import Vocab, Pad\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import TransformerModel, InferTransformerModel, CrossEntropyCriterion, position_encoding_init\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "from utils import post_process_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00da175f-42e4-4051-a2d8-7eef2579bfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:52:14.934767Z",
     "iopub.status.busy": "2024-01-14T00:52:14.933876Z",
     "iopub.status.idle": "2024-01-14T00:52:14.942584Z",
     "shell.execute_reply": "2024-01-14T00:52:14.941873Z",
     "shell.execute_reply.started": "2024-01-14T00:52:14.934730Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 自定义读取本地数据的方法\n",
    "def read(src_path, tgt_path, is_predict=False):\n",
    "    if is_predict:\n",
    "        with open(src_path, 'r', encoding='utf8') as src_f:\n",
    "            for src_line in src_f.readlines():\n",
    "                src_line = src_line.strip()\n",
    "                if not src_line:\n",
    "                    continue\n",
    "                yield {'src':src_line, 'tgt':''}\n",
    "    else:\n",
    "        with open(src_path, 'r', encoding='utf8') as src_f, open(tgt_path, 'r', encoding='utf8') as tgt_f:\n",
    "            for src_line, tgt_line in zip(src_f.readlines(), tgt_f.readlines()):\n",
    "                src_line = src_line.strip()\n",
    "                if not src_line:\n",
    "                    continue\n",
    "                tgt_line = tgt_line.strip()\n",
    "                if not tgt_line:\n",
    "                    continue\n",
    "                yield {'src':src_line, 'tgt':tgt_line}\n",
    " # 过滤掉长度 ≤min_len或者≥max_len 的数据            \n",
    "def min_max_filer(data, max_len, min_len=0):\n",
    "    # 1 for special tokens.\n",
    "    data_min_len = min(len(data[0]), len(data[1])) + 1\n",
    "    data_max_len = max(len(data[0]), len(data[1])) + 1\n",
    "    return (data_min_len >= min_len) and (data_max_len <= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97f9f17-d13e-4751-abb4-1921babe7295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:53:24.578326Z",
     "iopub.status.busy": "2024-01-14T00:53:24.577521Z",
     "iopub.status.idle": "2024-01-14T00:53:24.590647Z",
     "shell.execute_reply": "2024-01-14T00:53:24.589910Z",
     "shell.execute_reply.started": "2024-01-14T00:53:24.578291Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建训练集、验证集的dataloader\n",
    "def create_data_loader(args):\n",
    "    train_dataset = load_dataset(read, src_path=args.training_file.split(',')[0], tgt_path=args.training_file.split(',')[1], lazy=False)\n",
    "    dev_dataset = load_dataset(read, src_path=args.validation_file.split(',')[0], tgt_path=args.validation_file.split(',')[1], lazy=False)\n",
    "\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    padding_vocab = (\n",
    "        lambda x: (x + args.pad_factor - 1) // args.pad_factor * args.pad_factor\n",
    "    )\n",
    "    args.src_vocab_size = padding_vocab(len(src_vocab))\n",
    "    args.trg_vocab_size = padding_vocab(len(trg_vocab))\n",
    "\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        target = sample['tgt'].split()\n",
    "\n",
    "        source = src_vocab.to_indices(source)\n",
    "        target = trg_vocab.to_indices(target)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    # 训练集dataloader和验证集dataloader\n",
    "    data_loaders = []\n",
    "    for i, dataset in enumerate([train_dataset, dev_dataset]):\n",
    "        dataset = dataset.map(convert_samples, lazy=False).filter(\n",
    "            partial(min_max_filer, max_len=args.max_length))\n",
    "\n",
    "        # BatchSampler: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/BatchSampler_cn.html\n",
    "        batch_sampler = BatchSampler(dataset,batch_size=args.batch_size, shuffle=True,drop_last=False)\n",
    "        \n",
    "        # DataLoader: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_sampler=batch_sampler,\n",
    "            collate_fn=partial(\n",
    "                prepare_train_input,\n",
    "                bos_idx=args.bos_idx,\n",
    "                eos_idx=args.eos_idx,\n",
    "                pad_idx=args.bos_idx),\n",
    "                num_workers=0,\n",
    "                return_list=True)\n",
    "        data_loaders.append(data_loader)\n",
    "\n",
    "    return data_loaders\n",
    "\n",
    "\n",
    "def prepare_train_input(insts, bos_idx, eos_idx, pad_idx):\n",
    "    \"\"\"\n",
    "    Put all padded data needed by training into a list.\n",
    "    \"\"\"\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad([inst[0] + [eos_idx] for inst in insts])\n",
    "    trg_word = word_pad([[bos_idx] + inst[1] for inst in insts])\n",
    "    lbl_word = np.expand_dims(\n",
    "        word_pad([inst[1] + [eos_idx] for inst in insts]), axis=2)\n",
    "\n",
    "    data_inputs = [src_word, trg_word, lbl_word]\n",
    "\n",
    "    return data_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9977bcb5-d29c-4f85-bf5c-42e87ec836aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:53:28.534372Z",
     "iopub.status.busy": "2024-01-14T00:53:28.533731Z",
     "iopub.status.idle": "2024-01-14T00:53:28.544410Z",
     "shell.execute_reply": "2024-01-14T00:53:28.543582Z",
     "shell.execute_reply.started": "2024-01-14T00:53:28.534340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 创建测试集的dataloader，原理步骤同上（创建训练集、验证集的dataloader）\n",
    "def create_infer_loader(args):\n",
    "    dataset = load_dataset(read, src_path=args.predict_file, tgt_path=None, is_predict=True, lazy=False)\n",
    "\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    padding_vocab = (\n",
    "        lambda x: (x + args.pad_factor - 1) // args.pad_factor * args.pad_factor\n",
    "    )\n",
    "    args.src_vocab_size = padding_vocab(len(src_vocab))\n",
    "    args.trg_vocab_size = padding_vocab(len(trg_vocab))\n",
    "\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        target = sample['tgt'].split()\n",
    "\n",
    "        source = src_vocab.to_indices(source)\n",
    "        target = trg_vocab.to_indices(target)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    dataset = dataset.map(convert_samples, lazy=False)\n",
    "\n",
    "    # BatchSampler: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/BatchSampler_cn.html\n",
    "    batch_sampler = BatchSampler(dataset,batch_size=args.infer_batch_size,drop_last=False)\n",
    "    \n",
    "    # DataLoader: https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=partial(\n",
    "            prepare_infer_input,\n",
    "            bos_idx=args.bos_idx,\n",
    "            eos_idx=args.eos_idx,\n",
    "            pad_idx=args.bos_idx),\n",
    "            num_workers=0,\n",
    "            return_list=True)\n",
    "    return data_loader, trg_vocab.to_tokens\n",
    "\n",
    "def prepare_infer_input(insts, bos_idx, eos_idx, pad_idx):\n",
    "    \"\"\"\n",
    "    Put all padded data needed by beam search decoder into a list.\n",
    "    \"\"\"\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad([inst[0] + [eos_idx] for inst in insts])\n",
    "\n",
    "    return [src_word, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45fd4ab-b071-43fb-9fd3-afdf4ac3afe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:53:33.501711Z",
     "iopub.status.busy": "2024-01-14T00:53:33.500716Z",
     "iopub.status.idle": "2024-01-14T00:53:33.517290Z",
     "shell.execute_reply": "2024-01-14T00:53:33.516482Z",
     "shell.execute_reply.started": "2024-01-14T00:53:33.501675Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_train(args):\n",
    "    # if args.use_gpu:\n",
    "    #     place = \"gpu\"\n",
    "    # else:\n",
    "    #     place = \"cpu\"\n",
    "    place = \"cpu\"\n",
    "    paddle.set_device(place)\n",
    "    # Set seed for CE\n",
    "    random_seed = eval(str(args.random_seed))\n",
    "    if random_seed is not None:\n",
    "        paddle.seed(random_seed)\n",
    "\n",
    "    # Define data loader\n",
    "    (train_loader), (eval_loader) = create_data_loader(args)\n",
    "\n",
    "    # Define model\n",
    "    transformer = TransformerModel(\n",
    "        src_vocab_size=args.src_vocab_size,\n",
    "        trg_vocab_size=args.trg_vocab_size,\n",
    "        max_length=args.max_length + 1,\n",
    "        n_layer = args.n_layer,\n",
    "        # num_encoder_layers=args.n_layer,\n",
    "        # num_decoder_layers=args.n_layer,\n",
    "        n_head=args.n_head,\n",
    "        d_model=args.d_model,\n",
    "        d_inner_hid=args.d_inner_hid,\n",
    "        dropout=args.dropout,\n",
    "        weight_sharing=args.weight_sharing,\n",
    "        bos_id=args.bos_idx,\n",
    "        eos_id=args.eos_idx)\n",
    "\n",
    "    # Define loss\n",
    "    criterion = CrossEntropyCriterion(args.label_smooth_eps, args.bos_idx)\n",
    "\n",
    "    scheduler = paddle.optimizer.lr.NoamDecay(\n",
    "        args.d_model, args.warmup_steps, args.learning_rate, last_epoch=0)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "        learning_rate=scheduler,\n",
    "        beta1=args.beta1,\n",
    "        beta2=args.beta2,\n",
    "        epsilon=float(args.eps),\n",
    "        parameters=transformer.parameters())\n",
    "\n",
    "    step_idx = 0\n",
    "\n",
    "    # Train loop\n",
    "    for pass_id in range(args.epoch):\n",
    "        batch_id = 0\n",
    "        for input_data in train_loader:\n",
    "\n",
    "            (src_word, trg_word, lbl_word) = input_data\n",
    "\n",
    "            logits = transformer(src_word=src_word, trg_word=trg_word)\n",
    "\n",
    "            sum_cost, avg_cost, token_num = criterion(logits, lbl_word)\n",
    "            \n",
    "            # 计算梯度\n",
    "            avg_cost.backward() \n",
    "            # 更新参数\n",
    "            optimizer.step() \n",
    "            # 梯度清零\n",
    "            optimizer.clear_grad() \n",
    "\n",
    "            if (step_idx + 1) % args.print_step == 0 or step_idx == 0:\n",
    "                total_avg_cost = avg_cost.numpy()\n",
    "                logger.info(\n",
    "                    \"step_idx: %d, epoch: %d, batch: %d, avg loss: %f, \"\n",
    "                    \" ppl: %f \" %\n",
    "                    (step_idx, pass_id, batch_id, total_avg_cost,\n",
    "                        np.exp([min(total_avg_cost, 100)])))\n",
    "\n",
    "            if (step_idx + 1) % args.save_step == 0:\n",
    "                # Validation\n",
    "                transformer.eval()\n",
    "                total_sum_cost = 0\n",
    "                total_token_num = 0\n",
    "                with paddle.no_grad():\n",
    "                    for input_data in eval_loader:\n",
    "                        (src_word, trg_word, lbl_word) = input_data\n",
    "                        logits = transformer(\n",
    "                            src_word=src_word, trg_word=trg_word)\n",
    "                        sum_cost, avg_cost, token_num = criterion(logits,\n",
    "                                                                  lbl_word)\n",
    "                        total_sum_cost += sum_cost.numpy()\n",
    "                        total_token_num += token_num.numpy()\n",
    "                        total_avg_cost = total_sum_cost / total_token_num\n",
    "                    logger.info(\"validation, step_idx: %d, avg loss: %f, \"\n",
    "                                \" ppl: %f\" %\n",
    "                                (step_idx, total_avg_cost,\n",
    "                                 np.exp([min(total_avg_cost, 100)])))\n",
    "                transformer.train()\n",
    "\n",
    "                if args.save_model:\n",
    "                    model_dir = os.path.join(args.save_model,\n",
    "                                             \"step_\" + str(step_idx))\n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.makedirs(model_dir)\n",
    "                    paddle.save(transformer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "                    paddle.save(optimizer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdopt\"))\n",
    "            batch_id += 1\n",
    "            step_idx += 1\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "    if args.save_model:\n",
    "        model_dir = os.path.join(args.save_model, \"step_final\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        paddle.save(transformer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "        paddle.save(optimizer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdopt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57858bea-9d42-4c64-86a4-149d75c93091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:53:38.037528Z",
     "iopub.status.busy": "2024-01-14T00:53:38.036901Z",
     "iopub.status.idle": "2024-01-14T00:53:38.164509Z",
     "shell.execute_reply": "2024-01-14T00:53:38.163287Z",
     "shell.execute_reply.started": "2024-01-14T00:53:38.037493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4,\r\n",
      " 'beam_size': 5,\r\n",
      " 'beta1': 0.9,\r\n",
      " 'beta2': 0.997,\r\n",
      " 'bos_idx': 0,\r\n",
      " 'd_inner_hid': 2048,\r\n",
      " 'd_model': 512,\r\n",
      " 'dropout': 0.1,\r\n",
      " 'eos_idx': 1,\r\n",
      " 'epoch': 1,\r\n",
      " 'eps': '1e-9',\r\n",
      " 'infer_batch_size': 4,\r\n",
      " 'init_from_params': 'trained_models/CWMT2021_step_345000/',\r\n",
      " 'label_smooth_eps': 0.1,\r\n",
      " 'learning_rate': 2.0,\r\n",
      " 'max_length': 256,\r\n",
      " 'max_out_len': 256,\r\n",
      " 'n_best': 1,\r\n",
      " 'n_head': 8,\r\n",
      " 'n_layer': 6,\r\n",
      " 'output_file': 'train_dev_test/predict.txt',\r\n",
      " 'pad_factor': 8,\r\n",
      " 'predict_file': 'train_dev_test/ccmt2019-news.zh2en.source_bpe',\r\n",
      " 'print_step': 10,\r\n",
      " 'random_seed': 'None',\r\n",
      " 'save_model': 'trained_models',\r\n",
      " 'save_step': 20,\r\n",
      " 'special_token': ['<s>', '<e>', '<unk>'],\r\n",
      " 'src_vocab_fpath': 'train_dev_test/vocab.ch.src',\r\n",
      " 'src_vocab_size': 10000,\r\n",
      " 'training_file': 'train_dev_test/train.ch.bpe,train_dev_test/train.en.bpe',\r\n",
      " 'trg_vocab_fpath': 'train_dev_test/vocab.en.tgt',\r\n",
      " 'trg_vocab_size': 10000,\r\n",
      " 'unk_idx': 2,\r\n",
      " 'use_gpu': True,\r\n",
      " 'validation_file': 'train_dev_test/dev.ch.bpe,train_dev_test/dev.en.bpe',\r\n",
      " 'warmup_steps': 8000,\r\n",
      " 'weight_sharing': False}\r\n"
     ]
    }
   ],
   "source": [
    "# 读入参数\n",
    "yaml_file = 'transformer.base.yaml'\n",
    "with open(yaml_file, 'rt') as f:\n",
    "    args = AttrDict(yaml.safe_load(f))\n",
    "    pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a082596-ebe4-4f42-ae79-d9b96a2423bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:53:42.652241Z",
     "iopub.status.busy": "2024-01-14T00:53:42.651717Z",
     "iopub.status.idle": "2024-01-14T01:05:18.043657Z",
     "shell.execute_reply": "2024-01-14T01:05:18.042530Z",
     "shell.execute_reply.started": "2024-01-14T00:53:42.652209Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-14 08:53:47,417] [    INFO] - step_idx: 0, epoch: 0, batch: 0, avg loss: 10.533161,  ppl: 37539.957031 \r\n",
      "[2024-01-14 08:54:00,609] [    INFO] - step_idx: 9, epoch: 0, batch: 9, avg loss: 10.532831,  ppl: 37527.574219 \r\n",
      "[2024-01-14 08:54:14,894] [    INFO] - step_idx: 19, epoch: 0, batch: 19, avg loss: 10.511075,  ppl: 36719.933594 \r\n",
      "[2024-01-14 08:54:25,711] [    INFO] - validation, step_idx: 19, avg loss: 10.501055,  ppl: 36353.828125\r\n",
      "[2024-01-14 08:55:04,129] [    INFO] - step_idx: 29, epoch: 0, batch: 29, avg loss: 10.458016,  ppl: 34822.410156 \r\n",
      "[2024-01-14 08:55:18,928] [    INFO] - step_idx: 39, epoch: 0, batch: 39, avg loss: 10.407685,  ppl: 33113.136719 \r\n",
      "[2024-01-14 08:55:29,908] [    INFO] - validation, step_idx: 39, avg loss: 10.434054,  ppl: 33997.914062\r\n",
      "[2024-01-14 08:55:57,559] [    INFO] - step_idx: 49, epoch: 0, batch: 49, avg loss: 10.377353,  ppl: 32123.806641 \r\n",
      "[2024-01-14 08:56:11,390] [    INFO] - step_idx: 59, epoch: 0, batch: 59, avg loss: 10.316057,  ppl: 30213.894531 \r\n",
      "[2024-01-14 08:56:21,963] [    INFO] - validation, step_idx: 59, avg loss: 10.352994,  ppl: 31350.765625\r\n",
      "[2024-01-14 08:56:49,953] [    INFO] - step_idx: 69, epoch: 0, batch: 69, avg loss: 10.262465,  ppl: 28637.302734 \r\n",
      "[2024-01-14 08:57:04,587] [    INFO] - step_idx: 79, epoch: 0, batch: 79, avg loss: 10.177380,  ppl: 26301.455078 \r\n",
      "[2024-01-14 08:57:15,643] [    INFO] - validation, step_idx: 79, avg loss: 10.260830,  ppl: 28590.503906\r\n",
      "[2024-01-14 08:57:44,822] [    INFO] - step_idx: 89, epoch: 0, batch: 89, avg loss: 10.090322,  ppl: 24108.566406 \r\n",
      "[2024-01-14 08:57:58,532] [    INFO] - step_idx: 99, epoch: 0, batch: 99, avg loss: 10.069500,  ppl: 23611.753906 \r\n",
      "[2024-01-14 08:58:09,409] [    INFO] - validation, step_idx: 99, avg loss: 10.148290,  ppl: 25547.369141\r\n",
      "[2024-01-14 08:58:37,918] [    INFO] - step_idx: 109, epoch: 0, batch: 109, avg loss: 9.866936,  ppl: 19282.162109 \r\n",
      "[2024-01-14 08:58:52,741] [    INFO] - step_idx: 119, epoch: 0, batch: 119, avg loss: 9.861669,  ppl: 19180.867188 \r\n",
      "[2024-01-14 08:59:04,089] [    INFO] - validation, step_idx: 119, avg loss: 10.013292,  ppl: 22321.203125\r\n",
      "[2024-01-14 08:59:32,604] [    INFO] - step_idx: 129, epoch: 0, batch: 129, avg loss: 9.803599,  ppl: 18098.771484 \r\n",
      "[2024-01-14 08:59:47,134] [    INFO] - step_idx: 139, epoch: 0, batch: 139, avg loss: 9.703584,  ppl: 16376.189453 \r\n",
      "[2024-01-14 08:59:57,800] [    INFO] - validation, step_idx: 139, avg loss: 9.851791,  ppl: 18992.345703\r\n",
      "[2024-01-14 09:00:25,682] [    INFO] - step_idx: 149, epoch: 0, batch: 149, avg loss: 9.596991,  ppl: 14720.415039 \r\n",
      "[2024-01-14 09:00:40,328] [    INFO] - step_idx: 159, epoch: 0, batch: 159, avg loss: 9.622265,  ppl: 15097.204102 \r\n",
      "[2024-01-14 09:00:51,392] [    INFO] - validation, step_idx: 159, avg loss: 9.665324,  ppl: 15761.479492\r\n",
      "[2024-01-14 09:01:19,386] [    INFO] - step_idx: 169, epoch: 0, batch: 169, avg loss: 9.527020,  ppl: 13725.633789 \r\n",
      "[2024-01-14 09:01:34,413] [    INFO] - step_idx: 179, epoch: 0, batch: 179, avg loss: 9.264916,  ppl: 10560.928711 \r\n",
      "[2024-01-14 09:01:45,580] [    INFO] - validation, step_idx: 179, avg loss: 9.465560,  ppl: 12907.450195\r\n",
      "[2024-01-14 09:02:13,345] [    INFO] - step_idx: 189, epoch: 0, batch: 189, avg loss: 9.151306,  ppl: 9426.745117 \r\n",
      "[2024-01-14 09:02:27,598] [    INFO] - step_idx: 199, epoch: 0, batch: 199, avg loss: 9.103327,  ppl: 8985.134766 \r\n",
      "[2024-01-14 09:02:38,541] [    INFO] - validation, step_idx: 199, avg loss: 9.253912,  ppl: 10445.347656\r\n",
      "[2024-01-14 09:03:07,212] [    INFO] - step_idx: 209, epoch: 0, batch: 209, avg loss: 9.131437,  ppl: 9241.294922 \r\n",
      "[2024-01-14 09:03:22,735] [    INFO] - step_idx: 219, epoch: 0, batch: 219, avg loss: 9.018792,  ppl: 8256.798828 \r\n",
      "[2024-01-14 09:03:33,491] [    INFO] - validation, step_idx: 219, avg loss: 9.030690,  ppl: 8355.625000\r\n",
      "[2024-01-14 09:04:01,161] [    INFO] - step_idx: 229, epoch: 0, batch: 229, avg loss: 8.727768,  ppl: 6171.936035 \r\n",
      "[2024-01-14 09:04:15,370] [    INFO] - step_idx: 239, epoch: 0, batch: 239, avg loss: 8.602707,  ppl: 5446.382812 \r\n",
      "[2024-01-14 09:04:25,967] [    INFO] - validation, step_idx: 239, avg loss: 8.821962,  ppl: 6781.559082\r\n",
      "[2024-01-14 09:04:53,909] [    INFO] - step_idx: 249, epoch: 0, batch: 249, avg loss: 8.453411,  ppl: 4691.046875 \r\n"
     ]
    }
   ],
   "source": [
    "do_train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471e9a9f-f41c-4bcf-8cfd-1c4bd0f09dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T01:09:14.475816Z",
     "iopub.status.busy": "2024-01-14T01:09:14.475118Z",
     "iopub.status.idle": "2024-01-14T01:09:14.485644Z",
     "shell.execute_reply": "2024-01-14T01:09:14.484835Z",
     "shell.execute_reply.started": "2024-01-14T01:09:14.475780Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_predict(args):\n",
    "    # if args.use_gpu:\n",
    "    #     place = \"gpu\"\n",
    "    # else:\n",
    "    #     place = \"cpu\"\n",
    "    place = \"cpu\"\n",
    "    paddle.set_device(place)\n",
    "\n",
    "    # Define data loader\n",
    "    test_loader, to_tokens = create_infer_loader(args)\n",
    "\n",
    "    # Define model\n",
    "    transformer = InferTransformerModel(\n",
    "        src_vocab_size=args.src_vocab_size,\n",
    "        trg_vocab_size=args.trg_vocab_size,\n",
    "        max_length=args.max_length + 1,\n",
    "        n_layer = args.n_layer,\n",
    "        # num_encoder_layers=args.n_layer,\n",
    "        # num_decoder_layers=args.n_layer,\n",
    "        n_head=args.n_head,\n",
    "        d_model=args.d_model,\n",
    "        d_inner_hid=args.d_inner_hid,\n",
    "        dropout=args.dropout,\n",
    "        weight_sharing=args.weight_sharing,\n",
    "        bos_id=args.bos_idx,\n",
    "        eos_id=args.eos_idx,\n",
    "        beam_size=args.beam_size,\n",
    "        max_out_len=args.max_out_len)\n",
    "\n",
    "    # Load the trained model\n",
    "    assert args.init_from_params, (\n",
    "        \"Please set init_from_params to load the infer model.\")\n",
    "\n",
    "    model_dict = paddle.load(\n",
    "        os.path.join(args.init_from_params, \"transformer.pdparams\"))\n",
    "\n",
    "    # To avoid a longer length than training, reset the size of position\n",
    "    # encoding to max_length\n",
    "    model_dict[\"encoder.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "    model_dict[\"decoder.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "    transformer.load_dict(model_dict)\n",
    "\n",
    "    # Set evaluate mode\n",
    "    transformer.eval()\n",
    "\n",
    "    f = open(args.output_file, \"w\")\n",
    "    with paddle.no_grad():\n",
    "        for (src_word, ) in test_loader:\n",
    "            finished_seq = transformer(src_word=src_word)\n",
    "            finished_seq = finished_seq.numpy().transpose([0, 2, 1])\n",
    "            for ins in finished_seq:\n",
    "                for beam_idx, beam in enumerate(ins):\n",
    "                    if beam_idx >= args.n_best:\n",
    "                        break\n",
    "                    id_list = post_process_seq(beam, args.bos_idx, args.eos_idx)\n",
    "                    word_list = to_tokens(id_list)\n",
    "                    sequence = \" \".join(word_list) + \"\\n\"\n",
    "                    f.write(sequence)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f3884a-b5b3-4bfd-8681-10789cdb676b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T01:09:16.653543Z",
     "iopub.status.busy": "2024-01-14T01:09:16.652890Z",
     "iopub.status.idle": "2024-01-14T01:15:47.982173Z",
     "shell.execute_reply": "2024-01-14T01:15:47.980956Z",
     "shell.execute_reply.started": "2024-01-14T01:09:16.653506Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/data/vocab.py:208: UserWarning: The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \r\n",
      "  \"The type of `to_tokens()`'s input `indices` is not `int` which will be forcibly transfered to `int`. \"\r\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4489/1619843556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4489/93510802.py\u001b[0m in \u001b[0;36mdo_predict\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mfinished_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mfinished_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinished_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinished_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/transformer/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_word)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         static_cache, enc_output, trg_src_attn_bias = TransformerBeamSearchDecoder.tile_beam_merge_with_batch(\n\u001b[0;32m--> 838\u001b[0;31m             (static_cache, enc_output, trg_src_attn_bias), self.beam_size)\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         rs, _ = nn.decode.dynamic_decode(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/transformer/modeling.py\u001b[0m in \u001b[0;36mtile_beam_merge_with_batch\u001b[0;34m(t, beam_size)\u001b[0m\n\u001b[1;32m    488\u001b[0m         return map_structure(\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeamSearchDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_beam_merge_with_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             t)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/transformer/modeling.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \"\"\"\n\u001b[1;32m    488\u001b[0m         return map_structure(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeamSearchDecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile_beam_merge_with_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             t)\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/rnn.py\u001b[0m in \u001b[0;36mtile_beam_merge_with_batch\u001b[0;34m(x, beam_size)\u001b[0m\n\u001b[1;32m    965\u001b[0m         x = nn.transpose(\n\u001b[1;32m    966\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             list(range(0, len(x.shape) - 1)))  # [batch_size * beam_size, ...]\n\u001b[0m\u001b[1;32m    968\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m   5483\u001b[0m     \"\"\"\n\u001b[1;32m   5484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0min_dygraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5485\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "do_predict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9bd76-7148-4ba2-8caa-6ea8ba692252",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T17:42:11.392991Z",
     "iopub.status.idle": "2024-01-13T17:42:11.393307Z",
     "shell.execute_reply": "2024-01-13T17:42:11.393172Z",
     "shell.execute_reply.started": "2024-01-13T17:42:11.393159Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 还原 predict.txt 中的预测结果为 tokenize 后的数据\n",
    "# ! sed -r 's/(@@ )|(@@ ?$)//g' train_dev_test/predict.txt > train_dev_test/predict.tok.txt\n",
    "# # BLEU评估工具来源于 https://github.com/moses-smt/mosesdecoder.git\n",
    "# ! tar -zxf mosesdecoder.tar.gz\n",
    "# # 计算multi-bleu\n",
    "# ! perl mosesdecoder/scripts/generic/multi-bleu.perl train_dev_test/ccmt2019-news.zh2en.ref*.txt < train_dev_test/predict.tok.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
